{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ad Hoc Relevance Ranking System\n",
    "\n",
    "Main task: Extract document segments relevant to a set of keywords\n",
    "\n",
    "Secondary tasks:\n",
    "* Select words within the document segment to highlight for easier reading\n",
    "* Select the top-k most relevant document segments for each user given their keywords\n",
    "* Keep track of which document segments have been sent to which users and don't duplicate\n",
    "\n",
    "## Segmenting\n",
    "\n",
    "TODO: Make this more sophisticated so that the conceptual breaks between sections are respected\n",
    "\n",
    "Input: A set of documents\n",
    "\n",
    "Output:\n",
    "\n",
    "* All tokens from all documents\n",
    "* All tokens for each document\n",
    "* A set of document segments:\n",
    "    * the original text of the segment\n",
    "    * the tokens from that segment\n",
    "    * the page number that the start of the segment comes from (TODO: fix this, right now it's the end)\n",
    "    * the document filename that the segment comes from\n",
    "    \n",
    "Method:\n",
    "\n",
    "Go through each document line by line and collect nonoverlapping sets of lines that are each at least W tokens long. (W = 100)\n",
    "\n",
    "## Relevance score\n",
    "\n",
    "Input:\n",
    "\n",
    "* Set of candidate document segments\n",
    "* Set of keywords\n",
    "\n",
    "Output:\n",
    "\n",
    "A numeric score for each document segment, where a higher score is a better match to the keywords.\n",
    "Some documents may have a score of None if there were no useful tokens to compare to the keywords.\n",
    "\n",
    "Method:\n",
    "\n",
    "1. Compute inverse document frequency for each keyword\n",
    "\n",
    "    * I actually used inverse document proportion... but it's the same by a scaling factor\n",
    "    \n",
    "    * $\\frac{1}{\\mbox{# documents in which keyword appears + smoothing}}$\n",
    "    \n",
    "    * smoothing = 1\n",
    "\n",
    "2. Vectorize keywords and tokens in each document_segment\n",
    "\n",
    "3. For each document segment:\n",
    "\n",
    "    a. Get pairwise cosine similarity between each keyword and each token in the document segment\n",
    "    \n",
    "    b. Get average cosine similarity (across document segment tokens) for each keyword\n",
    "    \n",
    "    c. Sum average cosine similarity for each keyword, weighted by that keyword's inverse document frequency\n",
    "\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "### Precision\n",
    "\n",
    "This is easier to evaluate\n",
    "\n",
    "### Recall\n",
    "\n",
    "This is harder to evaluate\n",
    "\n",
    "## TODO\n",
    "\n",
    "* [ ] figure out appropriate casing\n",
    "* [ ] narrow down document set by metadata\n",
    "    * `metadata.csv`\n",
    "    * use `DocumentManager`\n",
    "* [ ] add more keywords\n",
    "* [ ] figure out sectioning so we get more coherent sections\n",
    "* [ ] try different vectors? e.g. contextual??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"loading language model\")\n",
    "# load language model (this takes a few minutes)\n",
    "model = api.load('word2vec-google-news-300')\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erindb/miniconda3/envs/ecj/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings loaded \n",
      "loading docs ... \n"
     ]
    }
   ],
   "source": [
    "vectors = model.wv\n",
    "del model\n",
    "vectors.init_sims(True) # normalize the vectors (!), so we can use the dot product as similarity measure\n",
    "\n",
    "print('embeddings loaded ')\n",
    "print('loading docs ... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.75537425e-02, -8.87633935e-02,  4.03469950e-02,\n",
       "        -3.66226584e-02, -2.70014517e-02, -4.50024195e-02,\n",
       "         9.00048390e-03, -4.56231423e-02, -9.99364033e-02,\n",
       "        -1.02807244e-03, -2.25012098e-02,  6.89002573e-02,\n",
       "        -4.03469950e-02,  1.15454480e-01, -2.77773552e-02,\n",
       "        -4.15884405e-02, -2.21908484e-02, -3.78641039e-02,\n",
       "         6.12963969e-03,  1.37334969e-02, -6.26930222e-02,\n",
       "         2.07942203e-02,  6.98313415e-02, -5.49339876e-02,\n",
       "        -1.01177849e-01, -1.13475928e-03,  2.99498849e-02,\n",
       "         1.31593272e-01, -4.00366336e-02,  2.52168719e-03,\n",
       "         6.83765218e-04, -6.82795346e-02,  2.18804870e-02,\n",
       "        -4.96578403e-02,  2.09494010e-02, -1.78457871e-02,\n",
       "         6.05204925e-02, -1.03971101e-02, -7.75903761e-02,\n",
       "        -2.76221745e-02,  6.54862747e-02,  9.31084529e-02,\n",
       "        -5.86583242e-02,  1.31593272e-01, -7.64265191e-03,\n",
       "         2.59927753e-03, -2.05614488e-03, -5.83479628e-02,\n",
       "        -4.55843459e-04, -6.85898960e-02, -1.43542197e-02,\n",
       "        -3.75537425e-02,  8.19354355e-02, -1.01798572e-01,\n",
       "         5.55547103e-02,  4.53127809e-02, -1.46490633e-01,\n",
       "         8.00732672e-02,  6.54862747e-02, -4.90371175e-02,\n",
       "        -5.92790470e-02,  7.79783260e-03, -1.80785581e-02,\n",
       "         3.38294059e-02, -1.52271113e-03, -7.87542295e-03,\n",
       "        -1.31903635e-02, -2.56048236e-02,  2.25012098e-02,\n",
       "         3.01050656e-02, -1.50835693e-01,  4.31402475e-02,\n",
       "         8.00732672e-02, -3.08809690e-02, -2.51392815e-02,\n",
       "        -1.11109421e-01,  2.60703657e-02, -2.52944622e-02,\n",
       "         6.05204925e-02, -1.16385566e-02, -7.16935098e-02,\n",
       "        -8.37976038e-02, -1.27868935e-01,  1.10178338e-02,\n",
       "         1.36559065e-02,  8.61253217e-03,  2.97947042e-02,\n",
       "        -3.36742215e-02, -9.34964046e-03,  9.24877301e-02,\n",
       "        -2.27921735e-03, -1.10488698e-01, -2.06390396e-02,\n",
       "        -3.41397664e-03,  8.44183266e-02, -4.86879610e-03,\n",
       "         9.15566459e-03, -9.69879702e-03,  2.36650649e-03,\n",
       "        -8.37976038e-02,  1.05522908e-01, -9.99364033e-02,\n",
       "        -9.12462845e-02, -1.55180749e-02,  4.56231423e-02,\n",
       "         1.20265083e-02,  4.81060334e-02,  9.27205011e-03,\n",
       "         6.02101311e-02, -9.99364033e-02,  7.60385673e-03,\n",
       "        -9.06255618e-02, -1.20265083e-02, -3.18120532e-02,\n",
       "         7.72800148e-02,  5.08992858e-02,  1.17937373e-02,\n",
       "        -6.54862747e-02,  3.21224146e-02, -1.08005807e-01,\n",
       "        -2.70014517e-02, -3.41397673e-02,  2.46737394e-02,\n",
       "         5.46236262e-02, -4.62438650e-02,  2.31219325e-02,\n",
       "        -6.79691732e-02,  1.86992809e-02,  2.73118131e-02,\n",
       "        -1.77003050e-04,  2.51392815e-02,  1.00557126e-01,\n",
       "        -3.22775953e-02, -6.14515767e-02,  3.92607301e-02,\n",
       "        -8.88409838e-03,  1.02419294e-02, -7.54178464e-02,\n",
       "        -7.32453167e-02,  5.43132648e-02,  2.21908484e-02,\n",
       "        -1.73026547e-02, -8.56597722e-02, -9.81518254e-03,\n",
       "         6.85898960e-02,  2.04838589e-02, -2.79325359e-02,\n",
       "         1.04281463e-01,  3.08809690e-02, -9.24877301e-02,\n",
       "         4.96578403e-02,  7.64265191e-03, -7.44867623e-02,\n",
       "         3.94159108e-02,  7.69696534e-02,  1.19489180e-02,\n",
       "         2.23460291e-02,  8.30216985e-03,  2.85532586e-02,\n",
       "        -9.24877301e-02, -2.06390396e-02, -1.70698836e-02,\n",
       "         5.77272400e-02, -3.08809690e-02,  4.75241058e-03,\n",
       "         2.36650649e-03,  6.36241063e-02,  9.38843563e-03,\n",
       "        -8.25561583e-02, -1.06764361e-01, -4.15884405e-02,\n",
       "        -6.45551905e-02, -1.21040985e-01,  4.28298861e-02,\n",
       "         1.27248215e-02,  5.83479628e-02,  3.97262722e-02,\n",
       "        -1.11109421e-01,  6.42448291e-02, -6.23826608e-02,\n",
       "        -2.20356677e-02, -9.77638736e-03, -2.07942203e-02,\n",
       "        -1.83113292e-02, -1.34813273e-03, -1.98631361e-02,\n",
       "        -4.93474789e-02, -4.25195247e-02,  6.67277258e-03,\n",
       "        -1.53628942e-02, -6.05204925e-02, -9.19445977e-03,\n",
       "        -3.67778391e-02,  5.70289278e-03, -6.54862747e-02,\n",
       "         3.04542226e-03,  4.62438650e-02,  4.12780792e-02,\n",
       "         6.20722994e-02, -7.54178464e-02,  3.44501287e-02,\n",
       "        -4.81060334e-02, -4.25195247e-02, -3.86400074e-02,\n",
       "        -6.61069974e-02, -1.15454480e-01,  9.80742350e-02,\n",
       "        -2.62255464e-02,  2.85532586e-02,  9.43498984e-02,\n",
       "         5.02785631e-02, -3.44501287e-02,  1.03971101e-02,\n",
       "        -5.43132648e-02,  5.36925420e-02,  1.04281463e-01,\n",
       "         5.74168796e-03, -1.04281463e-01, -2.62255464e-02,\n",
       "        -3.95710906e-03, -5.80376014e-02, -1.38110872e-02,\n",
       "         3.52260321e-02, -3.16568725e-02,  6.82795346e-02,\n",
       "         5.83479628e-02,  3.84848267e-02, -4.03469950e-02,\n",
       "         1.03195198e-02, -1.61387980e-01, -2.20356677e-02,\n",
       "         8.13147128e-02, -5.30718192e-02, -4.87267561e-02,\n",
       "         2.70014517e-02, -2.43633781e-02,  1.38110872e-02,\n",
       "         7.91421831e-02, -3.30534987e-02,  1.02419294e-01,\n",
       "         2.35874746e-02, -8.69012251e-02, -3.19672339e-02,\n",
       "         7.47971237e-02, -5.52443489e-02, -1.13592312e-01,\n",
       "        -1.98825332e-03,  5.33821806e-02, -1.08005807e-01,\n",
       "        -4.38385643e-03,  1.30933756e-03,  1.05522908e-01,\n",
       "        -6.51759133e-02,  6.42448291e-02,  1.14833757e-01,\n",
       "         3.94159108e-02, -4.62438650e-02,  4.40713353e-02,\n",
       "        -6.57966360e-02,  1.06143638e-01,  9.12462845e-02,\n",
       "         1.33843394e-03, -7.94525445e-02, -3.69330198e-02,\n",
       "         1.03040017e-01, -3.27431373e-02,  7.01417029e-02,\n",
       "        -3.52260321e-02, -4.90371175e-02, -3.04154269e-02,\n",
       "        -9.18670073e-02, -1.45869907e-02,  8.44183266e-02,\n",
       "         1.68836653e-01, -1.00091584e-02, -1.17355445e-03,\n",
       "         3.70882004e-02, -1.72250643e-02,  5.35373576e-03,\n",
       "         1.55180749e-02,  1.51301234e-03, -1.38110872e-02,\n",
       "         4.74853106e-02,  7.91421812e-03,  5.49339876e-02,\n",
       "         2.68462710e-02,  4.34506126e-02, -4.18988019e-02,\n",
       "         8.06939900e-02, -1.01643391e-02, -1.00091584e-02,\n",
       "         1.25696408e-02, -3.72433811e-02,  1.39662679e-02,\n",
       "        -1.53628942e-02,  3.75537425e-02, -8.00732672e-02,\n",
       "         1.87768713e-02, -8.93841162e-02, -2.99498849e-02],\n",
       "       [-7.17722578e-03, -5.84021136e-02, -3.74035984e-02,\n",
       "        -5.79304644e-04,  4.56061438e-02, -1.42396167e-01,\n",
       "         5.51210940e-02,  5.70076797e-03,  4.52780426e-02,\n",
       "        -6.52922466e-02, -5.47929928e-02, -3.10056154e-02,\n",
       "        -1.08273581e-01,  1.52567318e-02, -3.46147344e-02,\n",
       "        -8.65368359e-03,  2.50997841e-02, -3.10056154e-02,\n",
       "        -2.75605470e-02, -7.94006214e-02,  3.40405572e-03,\n",
       "        -3.49428356e-02,  4.75747548e-02, -7.41509944e-02,\n",
       "        -7.21823871e-02, -5.51210940e-02, -5.06507093e-03,\n",
       "         4.19970229e-02, -1.55028077e-02,  1.45185031e-02,\n",
       "        -2.19828170e-02,  3.97003107e-02, -2.93651074e-02,\n",
       "        -7.57915080e-02, -9.02279839e-03, -4.33094315e-02,\n",
       "         5.67616038e-02, -2.29671225e-02, -4.49499413e-02,\n",
       "        -1.18116634e-02, -5.51210940e-02,  1.79635715e-02,\n",
       "         8.46502557e-02,  1.24022461e-01, -6.02374319e-04,\n",
       "         1.59129351e-02,  4.82309572e-02, -1.04992557e-02,\n",
       "        -2.67402939e-02,  1.81276221e-02,  1.62082270e-01,\n",
       "         1.37802735e-02, -6.72608614e-02,  1.67331900e-02,\n",
       "         2.92010568e-02, -1.17460430e-01, -1.07617378e-01,\n",
       "         6.29955381e-02,  3.01853623e-02, -8.39940459e-02,\n",
       "        -5.64335026e-02,  6.52922466e-02, -9.84305292e-02,\n",
       "         6.23393338e-03, -3.77317034e-02, -9.64619145e-02,\n",
       "         3.50658759e-03,  1.91939529e-02, -1.03172621e-04,\n",
       "         2.87089031e-02,  2.29671225e-02, -3.60911936e-02,\n",
       "         7.41509944e-02, -8.03849325e-02,  3.23180221e-02,\n",
       "         1.86197739e-02, -9.51495096e-02,  1.06304966e-01,\n",
       "        -2.55304179e-03, -1.87838264e-02, -2.50997841e-02,\n",
       "         4.46218401e-02, -1.03680156e-01,  3.11696660e-02,\n",
       "         5.05276695e-02,  1.24678668e-02, -7.38228932e-02,\n",
       "         3.74035984e-02,  3.06775142e-02, -1.23366259e-01,\n",
       "         3.83879058e-02, -8.39940459e-02,  2.69043446e-02,\n",
       "        -6.72608614e-02, -4.32684179e-03,  1.13195106e-02,\n",
       "         1.06304966e-01,  9.51495115e-03,  3.33023295e-02,\n",
       "        -1.12867005e-01,  3.87160070e-02,  5.57773001e-02,\n",
       "         6.23393320e-02,  8.72750655e-02, -1.08273579e-02,\n",
       "        -7.51353055e-02,  1.61590111e-02,  3.62552442e-02,\n",
       "         1.88658517e-02, -5.05276695e-02, -5.51210940e-02,\n",
       "        -6.36517406e-02,  3.05134635e-02,  2.16547158e-02,\n",
       "         4.12690482e-04, -2.13266145e-02,  4.15048711e-02,\n",
       "         1.14015359e-02,  6.36517406e-02, -5.08557707e-02,\n",
       "        -8.00568312e-02,  4.59342450e-02, -4.36375327e-02,\n",
       "        -9.97429341e-02,  8.33378434e-02, -1.56873651e-03,\n",
       "        -8.79312679e-02, -8.66188630e-02, -3.01853623e-02,\n",
       "        -2.14906652e-02,  7.61196092e-02, -5.08557707e-02,\n",
       "        -6.33236393e-02, -2.78886501e-02,  2.80527007e-02,\n",
       "        -3.46147344e-02,  1.92759780e-03, -1.08929783e-01,\n",
       "         2.62481403e-02,  6.72608614e-03, -1.87838264e-02,\n",
       "        -3.21539715e-02, -5.34805879e-02,  2.21468676e-02,\n",
       "        -3.36304307e-02, -1.23366259e-01, -1.27959689e-02,\n",
       "         8.98998827e-02, -7.77601153e-02, -6.52922466e-02,\n",
       "         4.03565168e-02, -8.10411349e-02,  8.72750655e-02,\n",
       "         7.71039128e-02,  1.23038162e-02,  4.05205674e-02,\n",
       "        -2.29671225e-02, -1.05648763e-01,  3.19899209e-02,\n",
       "        -6.92294687e-02,  4.24481649e-03, -3.10056154e-02,\n",
       "        -2.05063587e-03, -4.39656340e-02, -9.44933072e-02,\n",
       "         9.58057120e-02,  1.27652090e-03, -9.92507767e-03,\n",
       "        -4.19970229e-02, -2.49357335e-02, -7.34947920e-02,\n",
       "        -3.69114475e-03, -1.55848330e-02, -1.09093832e-02,\n",
       "         2.83808019e-02,  1.25498921e-02,  5.80740124e-02,\n",
       "        -1.96040794e-02, -1.55028077e-02,  9.31808949e-02,\n",
       "        -4.95433658e-02, -6.10269271e-02, -5.15119769e-02,\n",
       "        -5.77459075e-02,  1.26647279e-01, -1.04992561e-01,\n",
       "        -3.83879058e-02,  1.18772835e-01,  1.96861047e-02,\n",
       "         2.07524356e-02,  4.73696925e-03, -5.29064098e-03,\n",
       "         6.29955381e-02,  5.84021136e-02, -8.59626606e-02,\n",
       "         5.11838757e-02, -7.17722578e-03, -3.70754972e-02,\n",
       "         5.47929928e-02,  1.03557121e-03, -5.74178062e-02,\n",
       "         1.07453326e-02, -3.39585319e-02, -1.08929783e-01,\n",
       "        -6.26674369e-02, -9.25246924e-02, -3.98643650e-02,\n",
       "         1.52567318e-02,  1.08929783e-01, -2.05883849e-02,\n",
       "        -3.82238552e-02, -1.08929783e-01,  4.10127193e-02,\n",
       "         5.90583161e-02,  3.39585319e-02,  5.61054014e-02,\n",
       "        -2.37873774e-02,  8.26816410e-02, -1.92759782e-02,\n",
       "         8.61267094e-03,  3.92081589e-02, -1.18116634e-02,\n",
       "        -5.57773001e-02,  1.48466043e-02, -2.31311731e-02,\n",
       "        -9.88406502e-03,  5.64335026e-02,  3.97003107e-02,\n",
       "        -3.54349911e-02,  1.52567318e-02, -3.26461233e-02,\n",
       "        -2.14906652e-02,  4.34734812e-03, -4.79028560e-02,\n",
       "        -8.98998827e-02, -3.46557470e-03,  8.36659446e-02,\n",
       "        -8.46502557e-02,  4.98714671e-02,  2.11625639e-02,\n",
       "         1.09585986e-01,  6.13550283e-02,  8.12051818e-03,\n",
       "        -6.68507349e-03, -6.16831295e-02, -5.28243817e-02,\n",
       "         5.34805879e-02, -2.72324458e-02, -1.06304966e-01,\n",
       "         4.13408205e-02, -3.47787850e-02,  5.90583161e-02,\n",
       "         1.17296381e-02,  1.14179410e-01,  2.55919378e-02,\n",
       "         4.59342450e-02,  6.13550283e-02, -3.87160070e-02,\n",
       "        -1.40263503e-02,  3.70754972e-02, -7.87444189e-02,\n",
       "        -5.34805879e-02,  2.73964964e-02,  3.24820727e-02,\n",
       "         1.00399137e-01,  4.98714671e-02, -3.98643650e-02,\n",
       "        -7.15261847e-02, -6.66046590e-02,  4.26532291e-02,\n",
       "        -1.03023954e-01,  6.52922466e-02,  8.39940459e-02,\n",
       "        -3.52709405e-02, -2.93651074e-02, -6.89013675e-02,\n",
       "         1.23858415e-02, -7.87444189e-02,  1.16804227e-01,\n",
       "        -7.64477104e-02,  1.68152153e-02, -9.12122875e-02,\n",
       "         1.07617378e-01,  1.46588427e-05,  9.84305292e-02,\n",
       "        -3.75676528e-02, -1.30420448e-02,  1.25498921e-02,\n",
       "         1.16804227e-01, -3.80598046e-02, -1.19429037e-01,\n",
       "        -6.84912410e-03, -2.34592762e-02,  1.43544516e-02,\n",
       "         4.62623462e-02,  2.85448525e-02, -4.18329723e-02,\n",
       "        -2.41154786e-02,  4.72466536e-02, -1.23858415e-02]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectors[[\"ADU\", \"housing\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['housing', 'affordable', 'homelessness', 'ADU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30647\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n"
     ]
    }
   ],
   "source": [
    "directory = '../data/legistar_corpus'\n",
    "import os\n",
    "from autolocal.nlp import Tokenizer\n",
    "from gensim.parsing.preprocessing import *\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "documents = []\n",
    "document_sections = []\n",
    "# section_length = 20 # lines\n",
    "section_length = 100 # tokens\n",
    "min_section_length = 5\n",
    "\n",
    "docs_tokens = []\n",
    "\n",
    "# TODO: is lowercasing necessary?\n",
    "preprocess_filters = [\n",
    "    lambda x: x.lower(),\n",
    "    strip_punctuation,\n",
    "    strip_numeric,\n",
    "    strip_non_alphanum,\n",
    "    strip_multiple_whitespaces,\n",
    "    strip_numeric,\n",
    "    remove_stopwords,\n",
    "    strip_short\n",
    "]\n",
    "\n",
    "i=0\n",
    "print(len(os.listdir(directory)))\n",
    "for filename in os.listdir(directory): \n",
    "    with open (os.path.join(directory, filename)) as f: \n",
    "        document_tokens = []\n",
    "        document_str = f.read()\n",
    "        document_segment_lines = []\n",
    "        document_segment_tokens = []\n",
    "        document_tokens = []\n",
    "#         if i<100:\n",
    "        if True:\n",
    "            pages = document_str.split('\\f')\n",
    "            for p, page in enumerate(pages): \n",
    "                lines = page.split('\\n')\n",
    "                for line in lines:\n",
    "                    line_tokens = preprocess_string(line, filters=preprocess_filters)\n",
    "                    document_segment_lines.append(line)\n",
    "                    document_segment_tokens += line_tokens\n",
    "                    document_tokens += line_tokens\n",
    "                    docs_tokens += line_tokens\n",
    "                    if len(document_segment_tokens) >= section_length:\n",
    "                        document_sections.append((\n",
    "                            document_segment_tokens,\n",
    "                            p,\n",
    "                            filename,\n",
    "                            \"\\n\".join(document_segment_lines)\n",
    "                        ))\n",
    "                        document_segment_lines = []\n",
    "                        document_segment_tokens = []\n",
    "                if len(document_segment_tokens) >= min_section_length:\n",
    "                    document_sections.append((\n",
    "                        document_segment_tokens,\n",
    "                        p,\n",
    "                        filename,\n",
    "                        \"\\n\".join(document_segment_lines)\n",
    "                    ))\n",
    "                    document_segment_lines = []\n",
    "                    document_segment_tokens = []\n",
    "                documents.append(document_tokens)           \n",
    "        i+=1\n",
    "        if i%100 == 0:\n",
    "            print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405326\n",
      "(['city', 'santa', 'clara', 'canceled', 'planning', 'commission', 'wednesday', 'july', 'city', 'hall', 'council', 'chambers', 'meeting', 'canceled', 'planning', 'commission', 'meeting', 'scheduled', 'july', 'canceled', 'items', 'scheduled', 'regular', 'scheduled', 'meeting', 'wednesday', 'july', 'city', 'council', 'chambers', 'city', 'santa', 'clara', 'city', 'santa', 'clara', 'page', 'printed'], 0, 'Santa-Clara_2018-07-11_Planning-Commission_Agenda.txt', 'City of Santa Clara\\n\\nCANCELED\\n\\n Planning Commission\\n\\nWednesday, July 11, 2018\\n\\n7:00 PM\\n\\nCity Hall Council Chambers\\n\\n– MEETING CANCELED –\\n\\nThe Planning Commission Meeting \\n\\nscheduled for July 11, 2018, at 7:00 p.m. has been canceled.\\n\\n(No Items Scheduled)\\n\\nThe next regular scheduled meeting will be on Wednesday, July 25, 2018, at \\n\\n7:00 p.m. in the City Council Chambers of the City of Santa Clara.\\n\\nCity of Santa Clara\\n\\nPage 1 of 1 \\n\\nPrinted on 7/2/2018\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "print(len(document_sections))\n",
    "print(document_sections[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(document_sections[0])\n",
    "# print(document_sections[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inverse document frequency for each keyword\n",
    "* For each document section, for each keyword, get average document similarity\n",
    "    * for each word in the document section, for each keyword, get similarity of word vectors\n",
    "    * average across the document\n",
    "* For each document section, sum average document similarity, weighted by keyword inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter(docs_tokens)\n",
    "smoothing = 1\n",
    "# smoothing = 100\n",
    "doc_freqs = {}\n",
    "doc_freq_total = 0\n",
    "for w in word_counts:\n",
    "    if w in vectors:\n",
    "        doc_freqs[w] = word_counts[w] + smoothing\n",
    "        doc_freq_total += word_counts[w] + smoothing\n",
    "word_counts = None\n",
    "doc_props = {w: doc_freqs[w]/doc_freq_total for w in doc_freqs}\n",
    "inverse_doc_props = {w: (1/doc_props[w] if doc_props[w]>0 else 0) for w in doc_props}\n",
    "# inverse_doc_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_doc_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors = np.array([vectors[t] for t in keywords if t in inverse_doc_props])\n",
    "keyword_weights = np.array([inverse_doc_props[t] for t in keywords if t in inverse_doc_props])\n",
    "document_section_scores = []\n",
    "for s, section in enumerate(document_sections):\n",
    "        score = None\n",
    "        section_tokens = section[0]\n",
    "        # TODO: Zipf to figure out what the cutoff should be for normal communication\n",
    "        if len(set(section_tokens))<20:\n",
    "            score = 0\n",
    "        else:\n",
    "            section_vectors = np.array([vectors[t] for t in section_tokens if t in inverse_doc_props])\n",
    "            if section_vectors.shape[0]>0:\n",
    "    #             section_weights = np.array([inverse_doc_props[t] for t in section_tokens if t in inverse_doc_props])\n",
    "                similarities = cosine_similarity(section_vectors, keyword_vectors)\n",
    "    #             similarities = similarities * section_weights\n",
    "    #             similarities = similarities*(similarities>0.2)\n",
    "                keyword_similarities = np.mean(similarities, axis=0)\n",
    "    #             keyword_similarities = np.average(similarities, axis=0, weights=section_weights)\n",
    "                score = np.sum(keyword_similarities*keyword_weights)\n",
    "        document_section_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2670.7668517555016\n",
      "(['residents', 'living', 'poverty', 'level', 'families', 'incomes', 'poverty', 'level', 'specifically', 'extremely', 'low', 'low', 'incomes', 'greatest', 'risk', 'homeless', 'require', 'assistance', 'meeting', 'rent', 'mortgage', 'obligations', 'order', 'prevent', 'homelessness', 'census', 'data', 'suggest', 'percent', 'cupertino', 'residents', 'living', 'poverty', 'level', 'specifically', 'percent', 'family', 'households', 'percent', 'families', 'children', 'living', 'poverty', 'level', 'households', 'require', 'specific', 'housing', 'solutions', 'deeper', 'income', 'targeting', 'subsidies', 'housing', 'supportive', 'services', 'single', 'room', 'occupancy', 'units', 'rent', 'subsidies', 'vouchers', 'homeless', 'demand', 'emergency', 'transitional', 'shelter', 'cupertino', 'difficult', 'determine', 'given', 'episodic', 'nature', 'homelessness', 'generally', 'episodes', 'homelessness', 'families', 'individuals', 'occur', 'single', 'event', 'periodically', 'county', 'wide', 'santa', 'clara', 'county', 'homeless', 'census', 'survey', 'reported', 'point', 'time', 'count', 'homeless', 'people', 'streets', 'emergency', 'shelters', 'transitional', 'housing', 'domestic'], 461, 'Cupertino_2014-11-10_City-Council_Agenda.txt', 'Residents Living Below the Poverty Level\\n\\nFamilies with incomes below the poverty level, specifically \\nthose with extremely low and very low incomes, are at \\nthe greatest risk of becoming homeless and often require \\nassistance in meeting their rent and mortgage obligations \\nin order to prevent homelessness. Census data suggest \\nthat four percent of all Cupertino residents were living \\nbelow the poverty level in 2010. Specifically, about three \\npercent of family households and two percent of families \\nwith children were living below the poverty level. These \\nhouseholds may require specific housing solutions such \\nas deeper income targeting for subsidies, housing with \\nsupportive services, single-room occupancy units, or rent \\nsubsidies and vouchers.\\n\\nHomeless\\n\\nDemand for emergency and transitional shelter in \\nCupertino is difficult to determine given the episodic nature \\nof homelessness. Generally, episodes of homelessness \\namong families or individuals can occur as a single event \\nor periodically. The county-wide 2013 Santa Clara County \\nHomeless Census & Survey reported a point-in-time \\ncount of 7,631 homeless people on the streets and in \\nemergency shelters, transitional housing, and domestic ')\n"
     ]
    }
   ],
   "source": [
    "max_score = np.max(np.array([s for s in document_section_scores if s!=None]))\n",
    "print(max_score)\n",
    "best_doc_index = [i for i, s in enumerate(document_section_scores) if s==max_score][0]\n",
    "print(document_sections[best_doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = np.max(np.array([s for s in document_section_scores if s!=None]))\n",
    "best_doc_indices = [i for i, s in enumerate(document_section_scores) if s!=None and s>1500]\n",
    "# # print(len(best_doc_indices))\n",
    "# for i in best_doc_indices:\n",
    "#     print(document_sections[i][3])\n",
    "#     print(\"~~~~\")\n",
    "# # print(document_sections[best_doc_index])\n",
    "best_doc_segments = []\n",
    "for i in best_doc_indices:\n",
    "    tokens, p, filename, orig = document_sections[i]\n",
    "    score = document_section_scores[i]\n",
    "    best_doc_segments.append({\n",
    "        \"page_number\": p,\n",
    "        \"filename\": filename,\n",
    "        \"original_text\": orig,\n",
    "        \"relevance_score\": score\n",
    "    })\n",
    "pd.DataFrame(best_doc_segments).to_csv(\"best_doc_segments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keywords = keywords\n",
    "# How many documents does each keyword occur in?\n",
    "keyword_doc_counts = {k: 0 for k in all_keywords}\n",
    "keyword_doc_total = 0\n",
    "for document in documents:\n",
    "    for k in keyword_doc_counts:\n",
    "        if k in document:\n",
    "            keyword_doc_counts[k] += 1\n",
    "            keyword_doc_total += 1\n",
    "            \n",
    "keyword_section_counts = {k: 0 for k in all_keywords}\n",
    "keyword_section_total = 0\n",
    "for document in document_sections:\n",
    "    for k in keyword_section_counts:\n",
    "        if k in document[0]:\n",
    "            keyword_section_counts[k] += 1\n",
    "            keyword_section_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_doc_proportions = {k: keyword_doc_counts[k]/keyword_doc_total for k in keyword_doc_counts}\n",
    "keyword_section_proportions = {k: keyword_section_counts[k]/keyword_section_total for k in keyword_section_counts}\n",
    "print(keyword_doc_proportions)\n",
    "print(keyword_section_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_doc_freq = {k: 1/(keyword_doc_proportions[k]) if keyword_doc_proportions[k]>0 else 0 for k in keyword_doc_proportions}\n",
    "inverse_doc_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors = np.array([vectors[t] for t in keywords if t in vectors])\n",
    "keyword_weights = np.array([inverse_doc_freq[t] for t in keywords if t in vectors])\n",
    "document_section_scores = []\n",
    "for s, section in enumerate(document_sections):\n",
    "#     if s < 10:\n",
    "        score = None\n",
    "        section_tokens = section[0]\n",
    "#         print(\"read tokens\")\n",
    "        # get word vectors\n",
    "        section_vectors = np.array([vectors[t] for t in section_tokens if t in vectors])\n",
    "#         print(\"word vectors looked up\")\n",
    "        if section_vectors.shape[0]>0:\n",
    "            similarities = cosine_similarity(section_vectors, keyword_vectors)\n",
    "            similarities = similarities*(similarities>0.1)\n",
    "#             print(\"similarities computed\")\n",
    "            keyword_similarities = np.mean(similarities, axis=0)\n",
    "            score = np.sum(keyword_similarities*keyword_weights)\n",
    "        document_section_scores.append(score)\n",
    "# print(document_section_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = np.max(np.array([s for s in document_section_scores if s!=None]))\n",
    "print(max_score)\n",
    "best_doc_index = [i for i, s in enumerate(document_section_scores) if s==max_score][0]\n",
    "print(document_sections[best_doc_index])\n",
    "\n",
    "# max_score = np.max(np.array([s for s in document_section_scores if s!=None]))\n",
    "# best_doc_indices = [i for i, s in enumerate(document_section_scores) if s!=None and s>20]\n",
    "# best_doc_indices\n",
    "# for i in best_doc_indices:\n",
    "#     print(document_sections[i])\n",
    "# # print(document_sections[best_doc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why are these the same?\n",
    "print(\" \".join(document_sections[0][0]))\n",
    "print(\" \".join(document_sections[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1902841 , -0.        ,  0.12652467,  0.01557165],\n",
       "       [ 0.06678405,  0.04545134,  0.05078512,  0.29745492]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = cosine_similarity(np.array(vectors[[\"ADU\", \"applesauce\"]]), np.array(vectors[[\"housing\", \"after\", \"attachment\", \"cooking\"]]))\n",
    "sims*(sims>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['housing', 'affordable', 'homelessness', 'accessory', 'dwelling', 'unit', 'ADU']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.0360411 ,  0.03927992,  0.09836677],\n",
       "       [ 0.31637853, -0.06969636,  0.02391504,  0.14009611],\n",
       "       [ 0.45313504, -0.01476945,  0.01381858,  0.09197982],\n",
       "       [ 0.0892075 ,  0.03608286,  0.21938115,  0.07302914],\n",
       "       [ 0.40325326,  0.02292117,  0.17923255,  0.15913229],\n",
       "       [ 0.16630656,  0.12939759,  0.13552879,  0.03668242],\n",
       "       [ 0.1902841 , -0.09115382,  0.12652467,  0.01557165]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_keywords)\n",
    "cosine_similarity(np.array(vectors[all_keywords]), np.array(vectors[[\"housing\", \"after\", \"attachment\", \"cooking\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
